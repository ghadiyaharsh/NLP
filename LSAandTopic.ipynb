{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56abe3cd",
   "metadata": {},
   "source": [
    "# Implement LSA and Topic model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d09e7b",
   "metadata": {},
   "source": [
    "LSA (Latent Semantic Analysis)\n",
    "\n",
    "Topic Modeling (LDA – Latent Dirichlet Allocation)\n",
    "Both are used for discovering hidden topics/relationships in text documents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97edf0a3",
   "metadata": {},
   "source": [
    "## Understanding LSA (Latent Semantic Analysis)\n",
    "\n",
    "Goal: Reduce high-dimensional text data into fewer dimensions while preserving meaning.\n",
    "\n",
    "Works on the Term-Document Matrix created by TF-IDF.\n",
    "\n",
    "Uses SVD (Singular Value Decomposition) to reduce dimensions.\n",
    "\n",
    "Captures synonyms & semantic similarity.\n",
    "\n",
    "Example:\n",
    "Words: \"car\", \"automobile\"\n",
    "Both appear in similar contexts → LSA puts them closer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f152c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSA Topics (Word Importance):\n",
      "Topic 0 : ['learning', 'language', 'natural', 'machine', 'love']\n",
      "Topic 1 : ['apply', 'doctors', 'medicine', 'patients', 'treat']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# Sample documents\n",
    "documents = [\n",
    "    \"I love machine learning and natural language processing\",\n",
    "    \"Deep learning improves natural language understanding\",\n",
    "    \"Artificial intelligence and machine learning are related fields\",\n",
    "    \"Hospitals use AI to improve patient care\",\n",
    "    \"Doctors apply medicine to treat patients\"\n",
    "]\n",
    "\n",
    "# Step 1: TF-IDF\n",
    "vectorizer = TfidfVectorizer(stop_words='english')  \n",
    "X = vectorizer.fit_transform(documents) \n",
    "\n",
    "# Step 2: Apply LSA (using SVD)\n",
    "lsa_model = TruncatedSVD(n_components=2)  \n",
    "lsa_topic_matrix = lsa_model.fit_transform(X) \n",
    "print(\"LSA Topics (Word Importance):\")   \n",
    "terms = vectorizer.get_feature_names_out() \n",
    "for i, comp in enumerate(lsa_model.components_): \n",
    "    terms_comp = zip(terms, comp)\n",
    "    sorted_terms = sorted(terms_comp, key=lambda x: x[1], reverse=True)[:5]\n",
    "    print(\"Topic\", i, \":\", [t[0] for t in sorted_terms])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4e2f8a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LDA Topics (Word Importance):\n",
      "Topic 0 : ['machine', 'learning', 'love', 'processing', 'related']\n",
      "Topic 1 : ['improves', 'understanding', 'deep', 'treat', 'patients']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "# Step 1: Use same TF-IDF features\n",
    "lda_model = LatentDirichletAllocation(n_components=2, random_state=42)\n",
    "lda_matrix = lda_model.fit_transform(X)\n",
    "\n",
    "# Step 2: Print topics\n",
    "print(\"\\nLDA Topics (Word Importance):\")\n",
    "terms = vectorizer.get_feature_names_out()\n",
    "for i, topic in enumerate(lda_model.components_):\n",
    "    sorted_terms = [terms[i] for i in topic.argsort()[:-6:-1]]\n",
    "    print(\"Topic\", i, \":\", sorted_terms)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
